{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2db78c-a1d6-4257-9e5c-927933813d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6efe9b0b-2798-47f0-806a-beda3167f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv', encoding='utf-8')\n",
    "test =pd.read_csv('test.csv', encoding='utf-8')\n",
    "test_org=test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21be308d-cd77-4f98-9d2f-a185c0c0e499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>491.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date country              store             product  num_sold\n",
       "0   0  2010-01-01  Canada  Discount Stickers   Holographic Goose       NaN\n",
       "1   1  2010-01-01  Canada  Discount Stickers              Kaggle     973.0\n",
       "2   2  2010-01-01  Canada  Discount Stickers        Kaggle Tiers     906.0\n",
       "3   3  2010-01-01  Canada  Discount Stickers            Kerneler     423.0\n",
       "4   4  2010-01-01  Canada  Discount Stickers  Kerneler Dark Mode     491.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010a0999-3633-44c2-ac96-c880a3849bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "date           0\n",
      "country        0\n",
      "store          0\n",
      "product        0\n",
      "num_sold    8871\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "775d7a0d-f410-4b9c-b0a1-b710513a1af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "date       0\n",
      "country    0\n",
      "store      0\n",
      "product    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bbc4bbb-f709-49cf-858b-941805bf21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = train.select_dtypes(include=['float64', 'int32']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02d0deb-00d4-4089-bef4-5a17e6e5f2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_sold']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7dde487-5325-4d83-8e94-17d8591d67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col='date'\n",
    "def transform_date(df, col):\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "                             \n",
    "    df[f'{col}_year'] = df[col].dt.year.astype('float64')\n",
    "    df[f'{col}_month'] = df[col].dt.month.astype('float64')\n",
    "    df[f'{col}_day'] = df[col].dt.day.astype('float64')\n",
    "    df[f'{col}_day_of_week'] = df[col].dt.dayofweek.astype('float64')\n",
    "    df[f'{col}_hour'] = df[col].dt.hour.astype('float64')\n",
    "    df[f'{col}_minute'] = df[col].dt.minute.astype('float64')\n",
    "    \n",
    "    df[f'{col}_year_sin'] = np.sin(2 * np.pi * df[f'{col}_year'])\n",
    "    df[f'{col}_year_cos'] = np.cos(2 * np.pi * df[f'{col}_year'])\n",
    "    df[f'{col}_month_sin'] = np.sin(2 * np.pi * df[f'{col}_month'] / 12) \n",
    "    df[f'{col}_month_cos'] = np.cos(2 * np.pi * df[f'{col}_month'] / 12)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2957621-4e62-400b-a2bb-e818fb08874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transform_date(train, 'date')\n",
    "test = transform_date(test, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f214c6-e607-4d10-b64c-e69b2cde56fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_day_of_week</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_minute</th>\n",
       "      <th>date_year_sin</th>\n",
       "      <th>date_year_cos</th>\n",
       "      <th>date_month_sin</th>\n",
       "      <th>date_month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>973.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>906.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>423.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>491.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date country              store             product  num_sold  \\\n",
       "0   0 2010-01-01  Canada  Discount Stickers   Holographic Goose       NaN   \n",
       "1   1 2010-01-01  Canada  Discount Stickers              Kaggle     973.0   \n",
       "2   2 2010-01-01  Canada  Discount Stickers        Kaggle Tiers     906.0   \n",
       "3   3 2010-01-01  Canada  Discount Stickers            Kerneler     423.0   \n",
       "4   4 2010-01-01  Canada  Discount Stickers  Kerneler Dark Mode     491.0   \n",
       "\n",
       "   date_year  date_month  date_day  date_day_of_week  date_hour  date_minute  \\\n",
       "0     2010.0         1.0       1.0               4.0        0.0          0.0   \n",
       "1     2010.0         1.0       1.0               4.0        0.0          0.0   \n",
       "2     2010.0         1.0       1.0               4.0        0.0          0.0   \n",
       "3     2010.0         1.0       1.0               4.0        0.0          0.0   \n",
       "4     2010.0         1.0       1.0               4.0        0.0          0.0   \n",
       "\n",
       "   date_year_sin  date_year_cos  date_month_sin  date_month_cos  \n",
       "0  -1.370366e-13            1.0             0.5        0.866025  \n",
       "1  -1.370366e-13            1.0             0.5        0.866025  \n",
       "2  -1.370366e-13            1.0             0.5        0.866025  \n",
       "3  -1.370366e-13            1.0             0.5        0.866025  \n",
       "4  -1.370366e-13            1.0             0.5        0.866025  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f65be2dd-4f2a-479d-a8a6-1bfd55129e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = train.select_dtypes(include=['float64', 'int32']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b1477e-b250-470d-b99e-d3ed0b5a0eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_sold',\n",
       " 'date_year',\n",
       " 'date_month',\n",
       " 'date_day',\n",
       " 'date_day_of_week',\n",
       " 'date_hour',\n",
       " 'date_minute',\n",
       " 'date_year_sin',\n",
       " 'date_year_cos',\n",
       " 'date_month_sin',\n",
       " 'date_month_cos']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39f3c040-7330-41c9-8807-8163cca70b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sold                      1.000000\n",
      "country_Norway                0.444573\n",
      "product_Kaggle                0.356331\n",
      "store_Premium Sticker Mart    0.231209\n",
      "product_Kaggle Tiers          0.197389\n",
      "store_Stickers for Less       0.089933\n",
      "country_Singapore             0.073334\n",
      "date_day_of_week              0.069613\n",
      "date_month_sin                0.014119\n",
      "date_day                      0.001137\n",
      "date_month_cos               -0.001781\n",
      "country_Finland              -0.002843\n",
      "date_month                   -0.006255\n",
      "date_year                    -0.040462\n",
      "id                           -0.040866\n",
      "date                         -0.040936\n",
      "date_year_sin                -0.047414\n",
      "product_Kerneler Dark Mode   -0.075360\n",
      "country_Italy                -0.139527\n",
      "product_Kerneler             -0.145131\n",
      "country_Kenya                -0.449873\n",
      "date_hour                          NaN\n",
      "date_minute                        NaN\n",
      "date_year_cos                      NaN\n",
      "Name: num_sold, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "encoded_train = pd.get_dummies(train, columns=categorical_columns, drop_first=True)\n",
    "correlation_matrix = encoded_train.corr()\n",
    "correlation_with_target = correlation_matrix['num_sold'].sort_values(ascending=False)\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e02b0f5-fd30-4862-8f8e-849bbd46125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Apply LabelEncoder to all categorical columns\n",
    "label_encoders = {}  # To store the encoders for each column\n",
    "for col in train.select_dtypes(include=['object', 'category']).columns:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "    label_encoders[col] = le  # Save the encoder for inverse transform if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3326f0-fa0a-4c88-9253-3caf1ca7f3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c3f23b4-7cf4-4374-bf8a-37e63f5190a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_day_of_week</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_minute</th>\n",
       "      <th>date_year_sin</th>\n",
       "      <th>date_year_cos</th>\n",
       "      <th>date_month_sin</th>\n",
       "      <th>date_month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>973.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>906.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>423.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>491.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.370366e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  store  product  num_sold  date_year  date_month  date_day  \\\n",
       "1        0      0        1     973.0     2010.0         1.0       1.0   \n",
       "2        0      0        2     906.0     2010.0         1.0       1.0   \n",
       "3        0      0        3     423.0     2010.0         1.0       1.0   \n",
       "4        0      0        4     491.0     2010.0         1.0       1.0   \n",
       "5        0      2        0     300.0     2010.0         1.0       1.0   \n",
       "\n",
       "   date_day_of_week  date_hour  date_minute  date_year_sin  date_year_cos  \\\n",
       "1               4.0        0.0          0.0  -1.370366e-13            1.0   \n",
       "2               4.0        0.0          0.0  -1.370366e-13            1.0   \n",
       "3               4.0        0.0          0.0  -1.370366e-13            1.0   \n",
       "4               4.0        0.0          0.0  -1.370366e-13            1.0   \n",
       "5               4.0        0.0          0.0  -1.370366e-13            1.0   \n",
       "\n",
       "   date_month_sin  date_month_cos  \n",
       "1             0.5        0.866025  \n",
       "2             0.5        0.866025  \n",
       "3             0.5        0.866025  \n",
       "4             0.5        0.866025  \n",
       "5             0.5        0.866025  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['date','id'], axis=1, inplace=True)\n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "448c370e-e413-4674-a0b2-0fb310c32860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-02 07:43:08,271] A new study created in memory with name: no-name-4fa0818b-acce-4577-bd81-af60768d943b\n",
      "[I 2025-01-02 07:43:26,345] Trial 0 finished with value: 3.1358257217396486 and parameters: {'n_estimators': 1819, 'learning_rate': 0.0008385374629910217, 'max_depth': 5, 'min_child_weight': 36, 'subsample': 0.8406112550786355, 'colsample_bytree': 0.6825392176691383, 'gamma': 0.12529970277091232, 'reg_alpha': 0.7283159843207773}. Best is trial 0 with value: 3.1358257217396486.\n",
      "[I 2025-01-02 07:43:52,900] Trial 1 finished with value: 0.8506888365789037 and parameters: {'n_estimators': 1520, 'learning_rate': 0.009632549508514164, 'max_depth': 12, 'min_child_weight': 95, 'subsample': 0.48416122180114574, 'colsample_bytree': 0.4455042347590919, 'gamma': 0.16445086902919154, 'reg_alpha': 0.16704921584283233}. Best is trial 1 with value: 0.8506888365789037.\n",
      "[I 2025-01-02 07:44:12,296] Trial 2 finished with value: 0.2284690505367954 and parameters: {'n_estimators': 1203, 'learning_rate': 0.0050130484639527495, 'max_depth': 8, 'min_child_weight': 47, 'subsample': 0.8768793399739858, 'colsample_bytree': 0.7367415507405585, 'gamma': 0.3131933302039973, 'reg_alpha': 0.4708709739901422}. Best is trial 2 with value: 0.2284690505367954.\n",
      "[I 2025-01-02 07:44:55,382] Trial 3 finished with value: 1.2790955484262496 and parameters: {'n_estimators': 1735, 'learning_rate': 0.003967536994547495, 'max_depth': 20, 'min_child_weight': 32, 'subsample': 0.517971272625421, 'colsample_bytree': 0.4228437427593347, 'gamma': 0.28415522229407353, 'reg_alpha': 0.6831730301949562}. Best is trial 2 with value: 0.2284690505367954.\n",
      "[I 2025-01-02 07:45:00,007] Trial 4 finished with value: 6.075571411157329 and parameters: {'n_estimators': 267, 'learning_rate': 0.0038707165005999636, 'max_depth': 10, 'min_child_weight': 72, 'subsample': 0.7490415719578485, 'colsample_bytree': 0.32731684355692464, 'gamma': 0.3366118673597158, 'reg_alpha': 0.5944474634216093}. Best is trial 2 with value: 0.2284690505367954.\n",
      "[I 2025-01-02 07:45:09,648] Trial 5 finished with value: 8.201823258214993 and parameters: {'n_estimators': 428, 'learning_rate': 0.00042516042626436024, 'max_depth': 10, 'min_child_weight': 48, 'subsample': 0.9747851577730944, 'colsample_bytree': 0.4715940524318886, 'gamma': 0.7932570255088661, 'reg_alpha': 0.8934171698441923}. Best is trial 2 with value: 0.2284690505367954.\n",
      "[I 2025-01-02 07:45:24,581] Trial 6 finished with value: 0.9144204600738628 and parameters: {'n_estimators': 1037, 'learning_rate': 0.005214831114947229, 'max_depth': 7, 'min_child_weight': 43, 'subsample': 0.33530686708895946, 'colsample_bytree': 0.5052718365462273, 'gamma': 0.5364660780416023, 'reg_alpha': 0.2373460169712356}. Best is trial 2 with value: 0.2284690505367954.\n",
      "[I 2025-01-02 07:45:35,188] Trial 7 finished with value: 5.617674479884353 and parameters: {'n_estimators': 338, 'learning_rate': 0.0022770516126196486, 'max_depth': 18, 'min_child_weight': 11, 'subsample': 0.9796824956415537, 'colsample_bytree': 0.6025900850020878, 'gamma': 0.9979405476707842, 'reg_alpha': 0.9429004233948866}. Best is trial 2 with value: 0.2284690505367954.\n",
      "[I 2025-01-02 07:45:57,153] Trial 8 finished with value: 0.5046747741747756 and parameters: {'n_estimators': 1578, 'learning_rate': 0.002315476037769423, 'max_depth': 6, 'min_child_weight': 55, 'subsample': 0.9797954608707724, 'colsample_bytree': 0.7653696927752083, 'gamma': 0.41549769851089513, 'reg_alpha': 0.055517761059965184}. Best is trial 2 with value: 0.2284690505367954.\n",
      "[I 2025-01-02 07:46:31,235] Trial 9 finished with value: 0.10278836878943148 and parameters: {'n_estimators': 1317, 'learning_rate': 0.008503399395800849, 'max_depth': 12, 'min_child_weight': 73, 'subsample': 0.4025757741964028, 'colsample_bytree': 0.7746780855581916, 'gamma': 0.6818087897016085, 'reg_alpha': 0.26741377953082396}. Best is trial 9 with value: 0.10278836878943148.\n",
      "[I 2025-01-02 07:46:47,376] Trial 10 finished with value: 0.08761096555508201 and parameters: {'n_estimators': 865, 'learning_rate': 0.009796830413863044, 'max_depth': 14, 'min_child_weight': 100, 'subsample': 0.31307105914642874, 'colsample_bytree': 0.9722641457571202, 'gamma': 0.5868632333035041, 'reg_alpha': 0.395450458958472}. Best is trial 10 with value: 0.08761096555508201.\n",
      "[I 2025-01-02 07:47:04,034] Trial 11 finished with value: 0.08656435766155607 and parameters: {'n_estimators': 887, 'learning_rate': 0.009748290250498986, 'max_depth': 15, 'min_child_weight': 98, 'subsample': 0.3185025671442056, 'colsample_bytree': 0.9942600136234979, 'gamma': 0.6342489930261439, 'reg_alpha': 0.36047058061138665}. Best is trial 11 with value: 0.08656435766155607.\n",
      "[I 2025-01-02 07:47:17,501] Trial 12 finished with value: 0.09579500097280204 and parameters: {'n_estimators': 732, 'learning_rate': 0.007152667903047381, 'max_depth': 15, 'min_child_weight': 99, 'subsample': 0.3193431645259762, 'colsample_bytree': 0.9582112293753304, 'gamma': 0.6181298264750589, 'reg_alpha': 0.39922290999013177}. Best is trial 11 with value: 0.08656435766155607.\n",
      "[I 2025-01-02 07:47:39,239] Trial 13 finished with value: 0.06857716868192937 and parameters: {'n_estimators': 927, 'learning_rate': 0.009785334002380828, 'max_depth': 15, 'min_child_weight': 83, 'subsample': 0.5978242471708015, 'colsample_bytree': 0.9909792730805521, 'gamma': 0.7606614391385598, 'reg_alpha': 0.39601913140373785}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:47:53,171] Trial 14 finished with value: 0.16747060788384857 and parameters: {'n_estimators': 615, 'learning_rate': 0.0074844677840129395, 'max_depth': 16, 'min_child_weight': 81, 'subsample': 0.6220010056703162, 'colsample_bytree': 0.8613508265465013, 'gamma': 0.8403424140398744, 'reg_alpha': 0.32671208544437985}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:48:14,295] Trial 15 finished with value: 0.07422139388948008 and parameters: {'n_estimators': 940, 'learning_rate': 0.008022813293541962, 'max_depth': 17, 'min_child_weight': 85, 'subsample': 0.612834716304999, 'colsample_bytree': 0.8664627108396178, 'gamma': 0.78734251654374, 'reg_alpha': 0.5411995770976441}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:48:50,883] Trial 16 finished with value: 0.07410257423454368 and parameters: {'n_estimators': 1089, 'learning_rate': 0.007628899366766306, 'max_depth': 18, 'min_child_weight': 83, 'subsample': 0.6704572116154994, 'colsample_bytree': 0.849872433646087, 'gamma': 0.9796113853139699, 'reg_alpha': 0.5608349533257352}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:49:29,304] Trial 17 finished with value: 0.07207998168795193 and parameters: {'n_estimators': 1307, 'learning_rate': 0.00631858538439084, 'max_depth': 20, 'min_child_weight': 63, 'subsample': 0.7087491481108744, 'colsample_bytree': 0.8928574267331415, 'gamma': 0.9873753575884281, 'reg_alpha': 0.7317131844717362}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:49:42,817] Trial 18 finished with value: 1.93007229876679 and parameters: {'n_estimators': 1289, 'learning_rate': 0.006392054950909656, 'max_depth': 3, 'min_child_weight': 62, 'subsample': 0.7575257261121449, 'colsample_bytree': 0.8962668319895477, 'gamma': 0.88566410820434, 'reg_alpha': 0.8387934232016885}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:50:20,264] Trial 19 finished with value: 0.4033930122940374 and parameters: {'n_estimators': 1480, 'learning_rate': 0.005943572541410467, 'max_depth': 20, 'min_child_weight': 61, 'subsample': 0.5106908043354237, 'colsample_bytree': 0.5910616317625366, 'gamma': 0.7268256474549056, 'reg_alpha': 0.8005958189285911}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:50:48,754] Trial 20 finished with value: 0.11815139380168534 and parameters: {'n_estimators': 644, 'learning_rate': 0.008581063631714896, 'max_depth': 19, 'min_child_weight': 21, 'subsample': 0.7065199036740283, 'colsample_bytree': 0.9065010494713752, 'gamma': 0.9350099098427616, 'reg_alpha': 0.9980343681664048}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:51:24,506] Trial 21 finished with value: 0.10718633137170423 and parameters: {'n_estimators': 1081, 'learning_rate': 0.006610681519850439, 'max_depth': 18, 'min_child_weight': 84, 'subsample': 0.6753578111165796, 'colsample_bytree': 0.7995891897827665, 'gamma': 0.9948759108780273, 'reg_alpha': 0.6223784199762304}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:52:04,311] Trial 22 finished with value: 0.09226972041057366 and parameters: {'n_estimators': 1186, 'learning_rate': 0.008761607714632828, 'max_depth': 17, 'min_child_weight': 72, 'subsample': 0.5752278238494385, 'colsample_bytree': 0.8287914483568308, 'gamma': 0.9086401676813752, 'reg_alpha': 0.49753571232391075}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:52:47,297] Trial 23 finished with value: 0.07636231900887692 and parameters: {'n_estimators': 1405, 'learning_rate': 0.007432318712352528, 'max_depth': 20, 'min_child_weight': 88, 'subsample': 0.801170214973771, 'colsample_bytree': 0.9166883936034613, 'gamma': 0.0060478135706338865, 'reg_alpha': 0.7235037796900587}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:53:17,843] Trial 24 finished with value: 0.19980542944995727 and parameters: {'n_estimators': 1051, 'learning_rate': 0.009076738144053829, 'max_depth': 14, 'min_child_weight': 77, 'subsample': 0.5832056138088133, 'colsample_bytree': 0.6906527501285424, 'gamma': 0.7491847354354918, 'reg_alpha': 0.5846294818760361}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:53:46,806] Trial 25 finished with value: 0.19183653217880653 and parameters: {'n_estimators': 769, 'learning_rate': 0.005490414753399045, 'max_depth': 18, 'min_child_weight': 64, 'subsample': 0.6817244174809686, 'colsample_bytree': 0.9401085741526071, 'gamma': 0.8499592198708943, 'reg_alpha': 0.46332827703009005}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:54:31,542] Trial 26 finished with value: 0.09453867557995203 and parameters: {'n_estimators': 1683, 'learning_rate': 0.007875550593481424, 'max_depth': 13, 'min_child_weight': 91, 'subsample': 0.7401201799553107, 'colsample_bytree': 0.8433854561245774, 'gamma': 0.9479100505220697, 'reg_alpha': 0.6790893454466495}. Best is trial 13 with value: 0.06857716868192937.\n",
      "[I 2025-01-02 07:55:04,364] Trial 27 finished with value: 0.06567330375415874 and parameters: {'n_estimators': 1240, 'learning_rate': 0.006448802890074519, 'max_depth': 16, 'min_child_weight': 67, 'subsample': 0.45295911361751967, 'colsample_bytree': 0.9948772889555972, 'gamma': 0.4765642517507076, 'reg_alpha': 0.7714764479107313}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 07:55:58,495] Trial 28 finished with value: 0.06737026298990752 and parameters: {'n_estimators': 1991, 'learning_rate': 0.00420442756176877, 'max_depth': 15, 'min_child_weight': 67, 'subsample': 0.45017757256763713, 'colsample_bytree': 0.9877132274581295, 'gamma': 0.46261452144836074, 'reg_alpha': 0.7740187186698513}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 07:56:38,084] Trial 29 finished with value: 0.08289332538730203 and parameters: {'n_estimators': 1966, 'learning_rate': 0.0042063010820248235, 'max_depth': 10, 'min_child_weight': 56, 'subsample': 0.42232688728353185, 'colsample_bytree': 0.9929807926190619, 'gamma': 0.45746073231250756, 'reg_alpha': 0.7947528804170318}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 07:57:32,341] Trial 30 finished with value: 0.08109494344240158 and parameters: {'n_estimators': 1881, 'learning_rate': 0.0030054895436996036, 'max_depth': 16, 'min_child_weight': 38, 'subsample': 0.4482704866255173, 'colsample_bytree': 0.9412714551833963, 'gamma': 0.3967363334518504, 'reg_alpha': 0.9068388189846676}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 07:58:09,805] Trial 31 finished with value: 0.06993688830476777 and parameters: {'n_estimators': 1661, 'learning_rate': 0.0048302836923471764, 'max_depth': 14, 'min_child_weight': 67, 'subsample': 0.3738716864576232, 'colsample_bytree': 0.9980667068315042, 'gamma': 0.5267822046073853, 'reg_alpha': 0.7607005002512153}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 07:58:50,795] Trial 32 finished with value: 0.0790500372948517 and parameters: {'n_estimators': 1998, 'learning_rate': 0.004657626678596062, 'max_depth': 13, 'min_child_weight': 71, 'subsample': 0.3679895444171314, 'colsample_bytree': 0.9937653203021225, 'gamma': 0.5259406023020514, 'reg_alpha': 0.8340224025531819}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 07:59:29,755] Trial 33 finished with value: 0.6740335048870768 and parameters: {'n_estimators': 1797, 'learning_rate': 0.0015358941255568612, 'max_depth': 15, 'min_child_weight': 67, 'subsample': 0.47208397968066323, 'colsample_bytree': 0.9422899919741617, 'gamma': 0.2066427613216304, 'reg_alpha': 0.75598817396967}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:00:04,871] Trial 34 finished with value: 0.2214541052063105 and parameters: {'n_estimators': 1630, 'learning_rate': 0.0035815221213485295, 'max_depth': 11, 'min_child_weight': 77, 'subsample': 0.5468595962203491, 'colsample_bytree': 0.7151240772783543, 'gamma': 0.46404258454797415, 'reg_alpha': 0.7022371527914889}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:00:46,784] Trial 35 finished with value: 0.07041839946897757 and parameters: {'n_estimators': 1854, 'learning_rate': 0.0047274209120362325, 'max_depth': 13, 'min_child_weight': 57, 'subsample': 0.3933793603154378, 'colsample_bytree': 0.9461223569109455, 'gamma': 0.24848923101615134, 'reg_alpha': 0.644439285293154}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:01:13,308] Trial 36 finished with value: 1.642739552818695 and parameters: {'n_estimators': 1475, 'learning_rate': 0.0032433940777307282, 'max_depth': 16, 'min_child_weight': 49, 'subsample': 0.4829903304647466, 'colsample_bytree': 0.322119566717877, 'gamma': 0.36510424413204445, 'reg_alpha': 0.8841461200544736}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:01:47,319] Trial 37 finished with value: 0.06846195830169655 and parameters: {'n_estimators': 1183, 'learning_rate': 0.005574976830840114, 'max_depth': 14, 'min_child_weight': 91, 'subsample': 0.36357654465022776, 'colsample_bytree': 0.9979605560775027, 'gamma': 0.5718510991485216, 'reg_alpha': 0.1537836611707536}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:02:19,792] Trial 38 finished with value: 0.31679137848521594 and parameters: {'n_estimators': 1187, 'learning_rate': 0.005694268165934798, 'max_depth': 11, 'min_child_weight': 92, 'subsample': 0.5297538420511115, 'colsample_bytree': 0.6273424609282408, 'gamma': 0.5770168005627688, 'reg_alpha': 0.07818875336854564}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:02:39,482] Trial 39 finished with value: 0.14252546616495815 and parameters: {'n_estimators': 963, 'learning_rate': 0.006622704098386332, 'max_depth': 8, 'min_child_weight': 77, 'subsample': 0.427409669932812, 'colsample_bytree': 0.8019769678691429, 'gamma': 0.6873971059450086, 'reg_alpha': 0.12176209366516277}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:02:53,727] Trial 40 finished with value: 1.0943516990265159 and parameters: {'n_estimators': 555, 'learning_rate': 0.0042629396220643925, 'max_depth': 12, 'min_child_weight': 93, 'subsample': 0.8893087761330289, 'colsample_bytree': 0.8897951689759094, 'gamma': 0.31682131793400303, 'reg_alpha': 0.2618991838734085}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:03:45,702] Trial 41 finished with value: 0.07346555198607264 and parameters: {'n_estimators': 1753, 'learning_rate': 0.005022050663414765, 'max_depth': 15, 'min_child_weight': 67, 'subsample': 0.37514077865298573, 'colsample_bytree': 0.9719923315734004, 'gamma': 0.4893154376840611, 'reg_alpha': 0.1787416814648695}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:04:22,509] Trial 42 finished with value: 0.22286021741809126 and parameters: {'n_estimators': 1561, 'learning_rate': 0.00258804237476977, 'max_depth': 14, 'min_child_weight': 51, 'subsample': 0.35625980620153985, 'colsample_bytree': 0.9954663832795303, 'gamma': 0.5504403377081147, 'reg_alpha': 0.1758624229935663}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:05:04,036] Trial 43 finished with value: 0.0843452359452629 and parameters: {'n_estimators': 1231, 'learning_rate': 0.004477563144564109, 'max_depth': 14, 'min_child_weight': 43, 'subsample': 0.45326648031923283, 'colsample_bytree': 0.9247107487230143, 'gamma': 0.42972572814117965, 'reg_alpha': 0.020858650236780907}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:05:39,912] Trial 44 finished with value: 1.713856590318959 and parameters: {'n_estimators': 1898, 'learning_rate': 0.0038026161502652403, 'max_depth': 17, 'min_child_weight': 79, 'subsample': 0.5012963011553876, 'colsample_bytree': 0.3724239112790301, 'gamma': 0.6628860048874259, 'reg_alpha': 0.4554035351001052}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:06:13,040] Trial 45 finished with value: 1.323154941810857 and parameters: {'n_estimators': 1415, 'learning_rate': 0.001434929270486246, 'max_depth': 13, 'min_child_weight': 87, 'subsample': 0.34536689781684793, 'colsample_bytree': 0.9665320245037154, 'gamma': 0.5123796689992491, 'reg_alpha': 0.6497977312755532}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:06:51,563] Trial 46 finished with value: 0.08175309052532415 and parameters: {'n_estimators': 1692, 'learning_rate': 0.005484341405401952, 'max_depth': 15, 'min_child_weight': 70, 'subsample': 0.3039590607571231, 'colsample_bytree': 0.9696431986071968, 'gamma': 0.3762391385397999, 'reg_alpha': 0.31508354854987164}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:07:09,680] Trial 47 finished with value: 0.12309279255625294 and parameters: {'n_estimators': 805, 'learning_rate': 0.0060037996095295455, 'max_depth': 16, 'min_child_weight': 76, 'subsample': 0.41550613093268124, 'colsample_bytree': 0.9992165574980382, 'gamma': 0.6014151621492798, 'reg_alpha': 0.7816380560429806}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:07:31,950] Trial 48 finished with value: 0.07653137895502682 and parameters: {'n_estimators': 966, 'learning_rate': 0.007050465666835058, 'max_depth': 12, 'min_child_weight': 58, 'subsample': 0.3919802852210185, 'colsample_bytree': 0.8887984063918615, 'gamma': 0.5652677052316891, 'reg_alpha': 0.9511015529588792}. Best is trial 27 with value: 0.06567330375415874.\n",
      "[I 2025-01-02 08:07:55,837] Trial 49 finished with value: 0.569659659476517 and parameters: {'n_estimators': 1142, 'learning_rate': 0.005179291194714569, 'max_depth': 14, 'min_child_weight': 67, 'subsample': 0.5428326143105808, 'colsample_bytree': 0.5659573705067944, 'gamma': 0.6470023900442758, 'reg_alpha': 0.41921287692737047}. Best is trial 27 with value: 0.06567330375415874.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt  # Imported for plotting\n",
    "\n",
    "# Assuming df1 is your original DataFrame with a column 'SalePrice'\n",
    "# Replace df1 with your actual data if necessary\n",
    "\n",
    "\n",
    "# Initialize StandardScaler objects\n",
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "\n",
    "# Separate features and target variable\n",
    "X= train.drop(columns=['num_sold'])\n",
    "y = train['num_sold']\n",
    "\n",
    "# Fit and transform the feature data\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "# Convert the scaled features back into a DataFrame with the original column names\n",
    "#X = pd.DataFrame(X, columns=train.columns)\n",
    "\n",
    "# Since SalePrice is the target, we scale it as well (for better model performance)\n",
    "\n",
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "def objective(trial):\n",
    "    \n",
    "    xgb_params = {\n",
    "        'device': 'cpu',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200,2000) ,\n",
    "        'learning_rate': trial.suggest_float('learning_rate',0.0001, 0.01), \n",
    "        'max_depth': trial.suggest_int('max_depth', 3,20), \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight',5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.3, 1.0), \n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0), \n",
    "        'gamma': trial.suggest_float('gamma', 0.001,1.0), \n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 1.0),\n",
    "        'enable_categorical':True,\n",
    "        'random_state':42\n",
    "        \n",
    "    }\n",
    "    model = XGBRegressor(**xgb_params)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "    return mape\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a32781b3-046a-4dfd-89dd-09efb96562a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1240,\n",
       " 'learning_rate': 0.006448802890074519,\n",
       " 'max_depth': 16,\n",
       " 'min_child_weight': 67,\n",
       " 'subsample': 0.45295911361751967,\n",
       " 'colsample_bytree': 0.9948772889555972,\n",
       " 'gamma': 0.4765642517507076,\n",
       " 'reg_alpha': 0.7714764479107313}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25f4c906-0f6b-4778-bbc2-f61c9f2404ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_day_of_week</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_minute</th>\n",
       "      <th>date_year_sin</th>\n",
       "      <th>date_year_cos</th>\n",
       "      <th>date_month_sin</th>\n",
       "      <th>date_month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230130</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.700862e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230131</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.700862e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230132</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.700862e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230133</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.700862e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230134</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.700862e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98545</th>\n",
       "      <td>328675</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.510335e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98546</th>\n",
       "      <td>328676</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.510335e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98547</th>\n",
       "      <td>328677</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.510335e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98548</th>\n",
       "      <td>328678</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.510335e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98549</th>\n",
       "      <td>328679</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.510335e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98550 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       date  country  store  product  date_year  date_month  \\\n",
       "0      230130 2017-01-01        0      0        0     2017.0         1.0   \n",
       "1      230131 2017-01-01        0      0        1     2017.0         1.0   \n",
       "2      230132 2017-01-01        0      0        2     2017.0         1.0   \n",
       "3      230133 2017-01-01        0      0        3     2017.0         1.0   \n",
       "4      230134 2017-01-01        0      0        4     2017.0         1.0   \n",
       "...       ...        ...      ...    ...      ...        ...         ...   \n",
       "98545  328675 2019-12-31        5      1        0     2019.0        12.0   \n",
       "98546  328676 2019-12-31        5      1        1     2019.0        12.0   \n",
       "98547  328677 2019-12-31        5      1        2     2019.0        12.0   \n",
       "98548  328678 2019-12-31        5      1        3     2019.0        12.0   \n",
       "98549  328679 2019-12-31        5      1        4     2019.0        12.0   \n",
       "\n",
       "       date_day  date_day_of_week  date_hour  date_minute  date_year_sin  \\\n",
       "0           1.0               6.0        0.0          0.0  -9.700862e-13   \n",
       "1           1.0               6.0        0.0          0.0  -9.700862e-13   \n",
       "2           1.0               6.0        0.0          0.0  -9.700862e-13   \n",
       "3           1.0               6.0        0.0          0.0  -9.700862e-13   \n",
       "4           1.0               6.0        0.0          0.0  -9.700862e-13   \n",
       "...         ...               ...        ...          ...            ...   \n",
       "98545      31.0               1.0        0.0          0.0   3.510335e-13   \n",
       "98546      31.0               1.0        0.0          0.0   3.510335e-13   \n",
       "98547      31.0               1.0        0.0          0.0   3.510335e-13   \n",
       "98548      31.0               1.0        0.0          0.0   3.510335e-13   \n",
       "98549      31.0               1.0        0.0          0.0   3.510335e-13   \n",
       "\n",
       "       date_year_cos  date_month_sin  date_month_cos  \n",
       "0                1.0    5.000000e-01        0.866025  \n",
       "1                1.0    5.000000e-01        0.866025  \n",
       "2                1.0    5.000000e-01        0.866025  \n",
       "3                1.0    5.000000e-01        0.866025  \n",
       "4                1.0    5.000000e-01        0.866025  \n",
       "...              ...             ...             ...  \n",
       "98545            1.0   -2.449294e-16        1.000000  \n",
       "98546            1.0   -2.449294e-16        1.000000  \n",
       "98547            1.0   -2.449294e-16        1.000000  \n",
       "98548            1.0   -2.449294e-16        1.000000  \n",
       "98549            1.0   -2.449294e-16        1.000000  \n",
       "\n",
       "[98550 rows x 15 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8922265-1190-4b7a-b9a4-22643f640972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[0]\tvalidation_0-rmse:687.04909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:19:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:19:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalidation_0-rmse:82.95207\n",
      "[1000]\tvalidation_0-rmse:62.60379\n",
      "[1239]\tvalidation_0-rmse:60.03471\n",
      "Mape Score is : 0.06725231328364854\n",
      "Fold 1\n",
      "[0]\tvalidation_0-rmse:685.26229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:19:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:19:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalidation_0-rmse:81.36580\n",
      "[1000]\tvalidation_0-rmse:61.11079\n",
      "[1239]\tvalidation_0-rmse:58.54512\n",
      "Mape Score is : 0.06767818960205661\n",
      "Fold 2\n",
      "[0]\tvalidation_0-rmse:687.45004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:20:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:20:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalidation_0-rmse:81.66830\n",
      "[1000]\tvalidation_0-rmse:61.67851\n",
      "[1239]\tvalidation_0-rmse:59.21199\n",
      "Mape Score is : 0.0680644532089777\n",
      "Fold 3\n",
      "[0]\tvalidation_0-rmse:687.91448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:20:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:20:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalidation_0-rmse:84.44459\n",
      "[1000]\tvalidation_0-rmse:63.44758\n",
      "[1239]\tvalidation_0-rmse:60.66538\n",
      "Mape Score is : 0.06787624519200722\n",
      "Fold 4\n",
      "[0]\tvalidation_0-rmse:681.59130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:21:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Rafid\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:21:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalidation_0-rmse:81.03479\n",
      "[1000]\tvalidation_0-rmse:61.54134\n",
      "[1239]\tvalidation_0-rmse:59.05680\n",
      "Mape Score is : 0.06874128322126148\n",
      "Mean MAPE: 0.06792249690159032, Std MAPE: 0.0004902109728453752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "new_test = test[X_train.columns]\n",
    "# Replace xgb_params with study.best_params\n",
    "xgb_params = study.best_params\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Add additional parameters that are not part of Optuna optimization but required\n",
    "xgb_params.update({\n",
    "    'device': 'gpu',                # Use GPU for training\n",
    "    'enable_categorical': True,     # Enable categorical feature support\n",
    "    'n_jobs': -1,                   # Use all available CPU threads\n",
    "})\n",
    "\n",
    "scores, xgb_test_preds = [], []\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "    print(f'Fold {i}')\n",
    "    X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]    \n",
    "\n",
    "    xgb_model = XGBRegressor(**xgb_params)\n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=500)\n",
    "\n",
    "    y_preds = xgb_model.predict(X_val)\n",
    "\n",
    "    mape_score = mean_absolute_percentage_error(y_val, y_preds)\n",
    "    print('Mape Score is :', mape_score)\n",
    "    scores.append(mape_score)\n",
    "    xgb_test_preds.append(xgb_model.predict(new_test))\n",
    "\n",
    "xgb_score = np.mean(scores)\n",
    "xgb_std = np.std(scores)\n",
    "\n",
    "print(f\"Mean MAPE: {xgb_score}, Std MAPE: {xgb_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "830cc442-69c9-44ec-bd98-ad0e47fa448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on the full dataset is complete. Predictions saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df1 is your original DataFrame with a column 'SalePrice' and df2 is the new test dataset\n",
    "# Ensure that df2 is loaded correctly\n",
    "X1_test = test  # Load the new test set\n",
    "\n",
    "# Align the columns of the test set with the columns of the training set (same features)\n",
    "X1_test = X1_test[X_train.columns]  # Ensure same feature columns in both training and test set\n",
    "\n",
    "\n",
    "# Make predictions with the trained model\n",
    "test_predictions_scaled = xgb_model.predict(X1_test)\n",
    "\n",
    "# If necessary, inverse transform the predictions (if they were scaled)\n",
    "#test_predictions = scaler_Y.inverse_transform(test_predictions_scaled.reshape(-1, 1))\n",
    "\n",
    "# Ensure 'Id' is correctly included as an integer column for saving the results\n",
    "\n",
    "# Save the predictions to a CSV file, including the 'Id' column\n",
    "predictions_df = pd.DataFrame({'id': test_org['id'], 'num_sold': test_predictions_scaled.flatten()})\n",
    "\n",
    "#predictions_df['id'] = predictions_df['id'].astype('Int32')\n",
    "predictions_df.to_csv('xgboost_predictions.csv', index=False)\n",
    "\n",
    "print(\"Training on the full dataset is complete. Predictions saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9470ff-180d-42be-ba2e-dfff526631f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
